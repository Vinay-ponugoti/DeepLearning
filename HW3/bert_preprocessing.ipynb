{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee7b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a022ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b50fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693e315",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a6a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, 'r') as f:\n",
    "        raw_data = json.load(f)\n",
    "    \n",
    "    dataset_questions, dataset_contexts, dataset_answers = zip(*[\n",
    "        (qa['question'].lower(), paragraph['context'].lower(), answer)\n",
    "        for group in raw_data['data']\n",
    "        for paragraph in group['paragraphs']\n",
    "        for qa in paragraph['qas']\n",
    "        for answer in qa['answers']\n",
    "    ])\n",
    "    \n",
    "    n_questions = len(dataset_questions)\n",
    "    num_pos = 0\n",
    "    num_imp = 0\n",
    "\n",
    "    return n_questions, num_pos, num_imp, list(dataset_contexts), list(dataset_questions), list(dataset_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4048a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "n_questions, num_pos, num_imp, train_contexts, train_questions, train_answers = get_data('spoken_train-v1.1.json')\n",
    "num_questions  = n_questions\n",
    "num_posible = num_pos\n",
    "num_imposible  = num_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a83611",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_questions, num_pos, num_imp, valid_contexts, valid_questions, valid_answers = get_data('spoken_test-v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43381d9b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def append_answer_end(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['text'] = answer['text'].lower()\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf56633",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "append_answer_end(train_answers, train_contexts)\n",
    "append_answer_end(valid_answers, valid_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f703c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_stride = 128\n",
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "pad_on_right = tokenizerFast.padding_side == \"right\"\n",
    "train_contexts_trunc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, context in enumerate(train_contexts):\n",
    "    if len(context) > MAX_LENGTH:\n",
    "        answer = train_answers[i]\n",
    "        mid = (answer['answer_start'] + answer['answer_end']) // 2\n",
    "        para_start = max(0, min(mid - MAX_LENGTH // 2, len(context) - MAX_LENGTH))\n",
    "        train_contexts_trunc.append(context[para_start:para_start + MAX_LENGTH])\n",
    "        train_answers[i]['answer_start'] = MAX_LENGTH // 2 - len(answer['text']) // 2\n",
    "    else:\n",
    "        train_contexts_trunc.append(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c980341",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings_fast = tokenizerFast(train_questions, train_contexts_trunc, max_length=MAX_LENGTH, truncation=True, stride=doc_stride, padding=True)\n",
    "valid_encodings_fast = tokenizerFast(valid_questions, valid_contexts, max_length=MAX_LENGTH, truncation=True, stride=doc_stride, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70499c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_start_end_train(idx):\n",
    "    ret_start, ret_end = 0, 0\n",
    "    answer_enc = tokenizerFast(train_answers[idx]['text'], max_length=MAX_LENGTH, truncation=True, padding=True)\n",
    "    enc_ids = train_encodings_fast['input_ids'][idx]\n",
    "    ans_ids = answer_enc['input_ids']\n",
    "    \n",
    "    for a in range(len(enc_ids) - len(ans_ids)):\n",
    "        if ans_ids[1:-1] == enc_ids[a + 1:a + len(ans_ids) - 1]:\n",
    "            ret_start, ret_end = a + 1, a + len(ans_ids) - 1\n",
    "            break\n",
    "\n",
    "    return ret_start, ret_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a11f34",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "start_positions = []\n",
    "end_positions = []\n",
    "ctr = 0\n",
    "for h, _ in enumerate(train_encodings_fast['input_ids']):\n",
    "    s, e = get_answer_start_end_train(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    ctr += (s == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8046e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "train_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956269c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_answer_start_end_valid(idx):\n",
    "    answer_encoding_fast = tokenizerFast(valid_answers[idx]['text'], max_length=MAX_LENGTH, truncation=True, padding=True)\n",
    "    for a in range(len(valid_encodings_fast['input_ids'][idx]) - len(answer_encoding_fast['input_ids'])):\n",
    "        for i in range(1, len(answer_encoding_fast['input_ids']) - 1):\n",
    "            if answer_encoding_fast['input_ids'][i] != valid_encodings_fast['input_ids'][idx][a + i]:\n",
    "                break\n",
    "        else:\n",
    "            return a+1, a+i+1\n",
    "    return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e8fe8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "start_positions, end_positions, ctr = [], [], 0\n",
    "for h, _ in enumerate(valid_encodings_fast['input_ids']):\n",
    "    s, e = get_answer_start_end_valid(h)\n",
    "    start_positions.append(s)\n",
    "    end_positions.append(e)\n",
    "    ctr += s == 0\n",
    "valid_encodings_fast.update({'start_positions': start_positions, 'end_positions': end_positions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6eca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][i]),\n",
    "            'token_type_ids': torch.tensor(self.encodings['token_type_ids'][i]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][i]),\n",
    "            'start_positions': torch.tensor(self.encodings['start_positions'][i]),\n",
    "            'end_positions': torch.tensor(self.encodings['end_positions'][i])\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InputDataset(train_encodings_fast)\n",
    "valid_dataset = InputDataset(valid_encodings_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c292a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39c65c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db685208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 * 2, 768 * 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(768 * 2, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        model_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = model_output.hidden_states\n",
    "        out = torch.cat((hidden_states[-1], hidden_states[-3]), dim=-1)\n",
    "        out = self.dropout(out)\n",
    "        logits = self.classifier(out)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        return start_logits.squeeze(-1), end_logits.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f9c14c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = QAModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33cd0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss_fn(start_logits, end_logits, start_positions, end_positions, gamma):\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    lsmax = nn.LogSoftmax(dim=1)\n",
    "    nll = nn.NLLLoss()\n",
    "\n",
    "    probs_start, probs_end = smax(start_logits), smax(end_logits)\n",
    "    inv_probs_start, inv_probs_end = 1 - probs_start, 1 - probs_end\n",
    "\n",
    "    log_probs_start, log_probs_end = lsmax(start_logits), lsmax(end_logits)\n",
    "\n",
    "    fl_start = nll(torch.pow(inv_probs_start, gamma) * log_probs_start, start_positions)\n",
    "    fl_end = nll(torch.pow(inv_probs_end, gamma) * log_probs_end, end_positions)\n",
    "    \n",
    "    return (fl_start + fl_end) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151673fc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "total_acc = []\n",
    "total_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, epoch):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f'Running Epoch {epoch}'):\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        del batch['start_positions']\n",
    "        del batch['end_positions']\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in batch.items()} \n",
    "        \n",
    "        # Forward pass\n",
    "        out_start, out_end = model(**batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = focal_loss_fn(out_start, out_end, start_positions, end_positions, gamma=1)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        start_pred, end_pred = torch.argmax(out_start, dim=1), torch.argmax(out_end, dim=1)\n",
    "        total_acc += ((start_pred == start_positions).float().mean() + (end_pred == end_positions).float().mean()) / 2\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    avg_acc = total_acc / num_batches\n",
    "    return avg_acc, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1123cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de09d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model.eval()\n",
    "    answer_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Running Evaluation'):\n",
    "            start_positions = batch['start_positions'].to(device)\n",
    "            end_positions = batch['end_positions'].to(device)\n",
    "            \n",
    "            del batch['start_positions']\n",
    "            del batch['end_positions']\n",
    "            \n",
    "            batch = {k: v.to(device) for k, v in batch.items()}  # Efficient device assignment\n",
    "            out_start, out_end = model(**batch)\n",
    "\n",
    "            start_pred = torch.argmax(out_start, dim=1)\n",
    "            end_pred = torch.argmax(out_end, dim=1)\n",
    "\n",
    "            for idx in range(len(batch['input_ids'])):\n",
    "                start_idx = int(start_pred[idx])\n",
    "                end_idx = int(end_pred[idx]) + 1  # +1 because the end index is exclusive\n",
    "                start_idx, end_idx = (start_idx, end_idx) if start_idx < end_idx else (end_idx, start_idx)  # Ensure correct ordering\n",
    "                \n",
    "                answer_pred = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(batch['input_ids'][idx][start_idx:end_idx]))\n",
    "                true_start = int(start_positions[idx])\n",
    "                true_end = int(end_positions[idx]) + 1  # +1 because the end index is exclusive\n",
    "                answer_true = tokenizerFast.convert_tokens_to_string(tokenizerFast.convert_ids_to_tokens(batch['input_ids'][idx][true_start:true_end]))\n",
    "                answer_list.append([answer_pred, answer_true])\n",
    "\n",
    "    return answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c074e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer = load(\"wer\")\n",
    "EPOCHS = 6\n",
    "model.to(device)\n",
    "wer_list = []\n",
    "print('Starting training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99404f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_acc, train_loss = train_epoch(model, train_data_loader, epoch + 1)\n",
    "    answer_list = eval_model(model, valid_data_loader)\n",
    "    \n",
    "    pred_answers, true_answers = zip(*[(ans[0] if ans[0] else \"$\", ans[1] if ans[1] else \"$\") for ans in answer_list])\n",
    "    \n",
    "    wer_score = wer.compute(predictions=pred_answers, references=true_answers)\n",
    "    wer_list.append(wer_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('WER (base model) - ',wer_list)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
